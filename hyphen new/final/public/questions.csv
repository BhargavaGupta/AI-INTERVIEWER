Explain Artificial Intelligence and give its applications.	Artificial Intelligence (AI) is a field of Computer Science that focuses on creating systems that can perform tasks that would typically require human intelligence, such as recognizing speech, understanding natural language, making decisions, and learning. Applications include image and speech recognition, natural language processing (NLP), robotics, and machine learning models like neural networks.
How are machine learning and AI related?	Machine learning is a subset of AI. While AI encompasses a broad range of technologies and approaches, machine learning specifically involves algorithms that learn from data. Many modern AI systems are based on machine learning techniques.
What is Deep Learning based on?	Deep learning is based on artificial neural networks with multiple layers (deep neural networks). It is inspired by the structure of the human brain and is effective at modeling complex patterns and representations in data.
How many layers are in a Neural Network?	Neural networks typically consist of three types of layers: input layer, hidden layer, and output layer.
Explain TensorFlow.	TensorFlow is an open-source platform developed by Google for high-performance numerical computation. It provides workflows to develop and train models efficiently and is highly customizable.
What are the pros of cognitive computing?	Pros of cognitive computing include enhanced understanding of human interaction, knowledge acquisition from data, and improved operational efficiency for enterprises.
Whatâ€™s the difference between NLP and NLU?	NLP (Natural Language Processing) involves processing and generating human language, while NLU (Natural Language Understanding) focuses on interpreting the meaning and intent behind the language.
Give some examples of weak and strong AI.	Weak AI examples: rule-based systems, decision trees. Strong AI examples: neural networks, deep learning models.
What is the need of data mining?	Data mining is used to discover patterns and insights from large datasets, aiding in decision-making and predictive analysis.
Name some sectors where data mining is applicable.	Data mining applications include healthcare (predicting patient outcomes), finance (predicting stock prices), and retail (predicting consumer behavior).
What are the components of NLP?	Components of NLP include language understanding, language generation, and language processing.
What is the full form of LSTM?	LSTM stands for Long Short-Term Memory, a type of recurrent neural network architecture used in various AI applications.
What is Artificial Narrow Intelligence (ANI)?	Artificial Narrow Intelligence (ANI), or Weak AI, refers to AI systems designed for specific tasks, performing them efficiently but lacking general intelligence.
What is a data cube?	A data cube is a multidimensional representation of data used to support complex analysis and modeling.
What is the difference between model accuracy and model performance?	Model accuracy measures how often a model correctly predicts outcomes, while model performance encompasses various metrics like accuracy, precision, recall, and F1 score.
What are different components of GAN?	GANs (Generative Adversarial Networks) consist of two components: the Generator, which creates synthetic data, and the Discriminator, which distinguishes between real and synthetic data.
What are common data structures used in deep learning?	Common data structures in deep learning include tensors, matrices, vectors, and arrays.
What is the role of the hidden layer in a neural network?	The hidden layer in a neural network extracts and learns features from input data, transforming it into a more useful form for the output layer.
Mention some advantages of neural networks.	Advantages of neural networks include their ability to handle large data, detect non-linear relationships, and adapt to changes in data.
What is the difference between stemming and lemmatization?	Stemming is a rule-based process that reduces words to their base forms, while lemmatization uses a dictionary to return the base form of a word.
What are the different types of text summarization?	Types of text summarization are extraction-based (using existing text) and abstraction-based (creating new phrases).
What is the meaning of corpus in NLP?	In NLP, a corpus is a large collection of texts used for various tasks such as building models or understanding language patterns.
Explain binarizing of data.	Binarizing of data converts data features into binary vectors to enhance the performance of classification algorithms.
What is perception and its types?	Perception involves interpreting sensory information and includes visual, auditory, and tactile types.
Give some pros and cons of decision trees.	Pros of decision trees: easy to understand and interpret. Cons: prone to overfitting.
Explain marginalization process.	Marginalization involves summing out certain variables from a joint distribution to focus on the remaining variables.
What is the function of an artificial neural network?	An artificial neural network simulates the human brain to learn from data and make predictions or classifications.
Explain cognitive computing and its types?	Cognitive computing aims to mimic human cognition using technologies like NLP, machine learning, and computer vision.
Explain the function of deep learning frameworks.	Deep learning frameworks provide tools for developing, training, and deploying deep learning models, simplifying complex processes.
How are speech recognition and video recognition different?	Speech recognition converts spoken language to text, while video recognition involves analyzing and understanding visual information from videos.
What is the pooling layer on CNN?	The pooling layer in CNNs reduces the dimensionality of feature maps by summarizing pooled areas, making the model more robust.
What is the purpose of Boltzmann machine?	Boltzmann machines are energy-based models used for learning probability distributions by simulating node interactions.
What do you mean by regular grammar?	Regular grammar specifies rules for forming strings from an alphabet, used to generate or validate strings.
How do you obtain data for NLP projects?	Data for NLP projects can be obtained from texts, transcripts, social media, web scraping, and other sources.
Explain regular expression in laymanâ€™s terms.	Regular expressions are patterns used to match and manipulate text. They describe text patterns and are used in programming and data processing.
How is NLTK different from spaCy?	NLTK is a general-purpose library with a broad range of NLP tools, while spaCy focuses on advanced tasks and is optimized for performance.
Name some best tools useful in NLP.	Best NLP tools include NLTK, spaCy, Gensim, and OpenNLP.
Are chatbots derived from NLP?	Yes, chatbots are derived from NLP as they use NLP techniques to understand and generate human language responses.
What is embedding and what are some techniques to accomplish embedding?	Embedding represents data in a vector space with similar data points close together. Techniques include word2vec and GloVe.
